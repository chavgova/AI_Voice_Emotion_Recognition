# My-AI

With the fast pace of development, machines soon will have the need to understand us on a higher level so they can be truly useful. A big part of understanding a human being is through their emotions.

We made various experiments and in our final model we extract 8 audio features (225 values) from human speech recordings for emotion recognition. We use a deep convolutional neural network trained on 4 audio datasets (RAVDESS, TESS, SAVEE, SER-v4). Our female model distinguishes 8 emotions with 94% accuracy and our male model recognizes 8 emotions with 89-90% accuracy.

In general, emotion recognition has great potential applicability for AIâ€™s future. It can be used for various human-machine interactions from customer experience and gaming to mental health care and security.
